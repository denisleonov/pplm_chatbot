{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Huggingface.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_-X0uHHlUbZ",
        "colab_type": "code",
        "outputId": "b9124f2e-d535-453b-a592-b09274039d1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/huggingface/transfer-learning-conv-ai.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'transfer-learning-conv-ai' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSWWdwWtlmXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VluhOdmTmczn",
        "colab_type": "code",
        "outputId": "434a3ea3-e77b-4d7d-839e-1f15a8b6e835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-ignite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/55/41e8a995876fd2ade29bdba0c3efefa38e7d605cb353c70f3173c04928b5/pytorch_ignite-0.3.0-py2.py3-none-any.whl (103kB)\n",
            "\r\u001b[K     |███▏                            | 10kB 18.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 92kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 102kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pytorch-ignite) (1.4.0)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIKTGTeTlvlN",
        "colab_type": "code",
        "outputId": "34e089b8-10b4-48ec-f78b-e5647b1e22a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python transfer-learning-conv-ai/interact.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transfer-learning-conv-ai/interact.py:Namespace(dataset_cache='./dataset_cache', dataset_path='', device='cpu', max_history=2, max_length=20, min_length=1, model='openai-gpt', model_checkpoint='', no_sample=False, seed=0, temperature=0.7, top_k=0, top_p=0.9)\n",
            "INFO:filelock:Lock 140697111338848 acquired on /root/.cache/torch/transformers/2f5114b5eb72f9515802779c42c1b289bebdb1cfc8ce94c653237518eb530b34.75f2a4fe69178ff43138117a977e107a5fc7d402603a0825a296b531f246b3f2.lock\n",
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/transfer-learning-chatbot/gpt_personachat_cache.tar.gz not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmplt71b2mi\n",
            "Downloading: 100% 434M/434M [00:06<00:00, 66.8MB/s]\n",
            "INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/transfer-learning-chatbot/gpt_personachat_cache.tar.gz in cache at /root/.cache/torch/transformers/2f5114b5eb72f9515802779c42c1b289bebdb1cfc8ce94c653237518eb530b34.75f2a4fe69178ff43138117a977e107a5fc7d402603a0825a296b531f246b3f2\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/2f5114b5eb72f9515802779c42c1b289bebdb1cfc8ce94c653237518eb530b34.75f2a4fe69178ff43138117a977e107a5fc7d402603a0825a296b531f246b3f2\n",
            "INFO:filelock:Lock 140697111338848 released on /root/.cache/torch/transformers/2f5114b5eb72f9515802779c42c1b289bebdb1cfc8ce94c653237518eb530b34.75f2a4fe69178ff43138117a977e107a5fc7d402603a0825a296b531f246b3f2.lock\n",
            "INFO:/content/transfer-learning-conv-ai/utils.py:extracting archive file /root/.cache/torch/transformers/2f5114b5eb72f9515802779c42c1b289bebdb1cfc8ce94c653237518eb530b34.75f2a4fe69178ff43138117a977e107a5fc7d402603a0825a296b531f246b3f2 to temp dir /tmp/tmpnkteypu0\n",
            "INFO:transfer-learning-conv-ai/interact.py:Get pretrained model and tokenizer\n",
            "INFO:transformers.tokenization_utils:Model name '/tmp/tmpnkteypu0' not found in model shortcut name list (openai-gpt). Assuming '/tmp/tmpnkteypu0' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "INFO:transformers.tokenization_utils:Didn't find file /tmp/tmpnkteypu0/special_tokens_map.json. We won't load it.\n",
            "INFO:transformers.tokenization_utils:Didn't find file /tmp/tmpnkteypu0/tokenizer_config.json. We won't load it.\n",
            "INFO:transformers.tokenization_utils:loading file /tmp/tmpnkteypu0/vocab.json\n",
            "INFO:transformers.tokenization_utils:loading file /tmp/tmpnkteypu0/merges.txt\n",
            "INFO:transformers.tokenization_utils:loading file /tmp/tmpnkteypu0/added_tokens.json\n",
            "INFO:transformers.tokenization_utils:loading file None\n",
            "INFO:transformers.tokenization_utils:loading file None\n",
            "WARNING:transformers.tokenization_openai:ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n",
            "INFO:transformers.configuration_utils:loading configuration file /tmp/tmpnkteypu0/config.json\n",
            "INFO:transformers.configuration_utils:Model config OpenAIGPTConfig {\n",
            "  \"afn\": \"gelu\",\n",
            "  \"architectures\": null,\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_ids\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"model_type\": \"openai-gpt\",\n",
            "  \"n_ctx\": 512,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 512,\n",
            "  \"n_special\": 5,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"predict_special_tokens\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 40483\n",
            "}\n",
            "\n",
            "INFO:transformers.modeling_utils:loading weights file /tmp/tmpnkteypu0/pytorch_model.bin\n",
            "INFO:transformers.modeling_utils:Weights from pretrained model not used in OpenAIGPTLMHeadModel: ['multiple_choice_head.summary.weight', 'multiple_choice_head.summary.bias']\n",
            "INFO:transformers.tokenization_utils:Assigning <bos> to the bos_token key of the tokenizer\n",
            "INFO:transformers.tokenization_utils:Assigning <eos> to the eos_token key of the tokenizer\n",
            "INFO:transformers.tokenization_utils:Assigning <pad> to the pad_token key of the tokenizer\n",
            "INFO:transformers.tokenization_utils:Assigning ['<speaker1>', '<speaker2>'] to the additional_special_tokens key of the tokenizer\n",
            "INFO:transfer-learning-conv-ai/interact.py:Sample a personality\n",
            "INFO:/content/transfer-learning-conv-ai/utils.py:Download dataset from https://s3.amazonaws.com/datasets.huggingface.co/personachat/personachat_self_original.json\n",
            "INFO:filelock:Lock 140697092555888 acquired on /root/.cache/torch/transformers/a6af0e86c91c9dc9b342b96c59adf0d1a4a7dc602d94b01ad47e0bfd19266632.bb42905dd6e1098e87c24845469ee12018cfd142e10fcc50f97b28e002a9ac02.lock\n",
            "INFO:transformers.file_utils:https://s3.amazonaws.com/datasets.huggingface.co/personachat/personachat_self_original.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpy5w3vl8n\n",
            "Downloading: 100% 210M/210M [00:04<00:00, 51.8MB/s]\n",
            "INFO:transformers.file_utils:storing https://s3.amazonaws.com/datasets.huggingface.co/personachat/personachat_self_original.json in cache at /root/.cache/torch/transformers/a6af0e86c91c9dc9b342b96c59adf0d1a4a7dc602d94b01ad47e0bfd19266632.bb42905dd6e1098e87c24845469ee12018cfd142e10fcc50f97b28e002a9ac02\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/a6af0e86c91c9dc9b342b96c59adf0d1a4a7dc602d94b01ad47e0bfd19266632.bb42905dd6e1098e87c24845469ee12018cfd142e10fcc50f97b28e002a9ac02\n",
            "INFO:filelock:Lock 140697092555888 released on /root/.cache/torch/transformers/a6af0e86c91c9dc9b342b96c59adf0d1a4a7dc602d94b01ad47e0bfd19266632.bb42905dd6e1098e87c24845469ee12018cfd142e10fcc50f97b28e002a9ac02.lock\n",
            "INFO:/content/transfer-learning-conv-ai/utils.py:Tokenize and encode the dataset\n",
            "\n",
            "Wq\n",
            "wqwqwqwqwqwq\n",
            "qwqwqwqwqwqw\n",
            "qwqwqwqwqwqw\n",
            "INFO:transfer-learning-conv-ai/interact.py:Selected personality: i grew up in the upstate. i live in the city. now i also work at a bank. my father used to work for a bank.\n",
            ">>> Prompt should not be empty!\n",
            ">>> hi how are you today\n",
            ">>> i'm good just got home from work\n",
            ">>> i work at a bank\n",
            ">>> oh wow that's so cool\n",
            ">>> So, what are you up to?\n",
            "working at the bank. you?\n",
            ">>> Talking with you\n",
            "that's cool! i'm in the city and i work at a bank\n",
            ">>> How do you spend your holydays?\n",
            "i like to work in the bank.\n",
            ">>> Where did your father worked?\n",
            "he used to work at a bank.\n",
            ">>> What do you choose - work in a bank or go to a movie?\n",
            "i like movies and movies.\n",
            ">>> And what about banks?\n",
            "do you work?\n",
            ">>> Yes\n",
            "what do you do?\n",
            ">>> I'm working in a bank?\n",
            "yes\n",
            ">>> And what about your mother?\n",
            "do you like her?\n",
            ">>> Yes. I am your father.\n",
            "what do you do for fun?\n",
            ">>> Work in a bank.\n",
            "do you have any hobbies?\n",
            ">>> Talking with strangers\n",
            "that is great. i'm not sure what i'd do without my mom\n",
            ">>> Oh, where did she work?\n",
            "she was a teller at the bank.\n",
            ">>> And what did she do for fun?\n",
            "i work at a bank and i enjoy being around people\n",
            ">>> Why do you like people?\n",
            "i love being around people.\n",
            ">>> Traceback (most recent call last):\n",
            "  File \"transfer-learning-conv-ai/interact.py\", line 154, in <module>\n",
            "    run()\n",
            "  File \"transfer-learning-conv-ai/interact.py\", line 140, in run\n",
            "    raw_text = input(\">>> \")\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}